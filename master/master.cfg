# -*- python -*-
# ex: set filetype=python:


import re
import os
import os.path
import sys
import collections
import importlib
import itertools

from twisted.logger import Logger
from twisted.internet import defer
import requests
import yaml

from buildbot.plugins import *
import buildbot.process.remotecommand

# See https://gist.github.com/joshbode/569627ced3076931b02f
class ConfigLoaderMeta(type):

    def __new__(metacls, __name__, __bases__, __dict__):
        """Add include constructer to class."""

        # register the include constructor on the class
        cls = super().__new__(metacls, __name__, __bases__, __dict__)
        cls.add_constructor('!include', cls.construct_include)

        return cls


class ConfigLoader(yaml.Loader, metaclass=ConfigLoaderMeta):
    """YAML Loader with `!include` constructor."""

    def __init__(self, stream):
        """Initialise Loader."""

        try:
            self._root = os.path.split(stream.name)[0]
        except AttributeError:
            self._root = os.path.curdir

        super().__init__(stream)

    def construct_include(self, node):
        """Include file referenced at node."""

        filename = os.path.abspath(os.path.join(
            self._root, self.construct_scalar(node)
        ))
        extension = os.path.splitext(filename)[1].lstrip('.')

        with open(filename, 'r') as f:
            return yaml.load(f, ConfigLoader)


# Hack to make basedir available in all other modules
basedir = os.path.expanduser(basedir)
import builtins
builtins.basedir = basedir

import packages as pkg
importlib.reload(pkg)

log = Logger('aur_buildbot')

####### CONFIGURATION VARIABLES

config_file = os.environ.get('AUR_BUILDBOT_CONFIG', '/etc/aur-buildbot/master/config.yml')

with open(config_file, 'r') as stream:
    config = yaml.load(stream)

poll_interval = config.get('poll_interval', 3600)

repo_config = config.get('repo', {})
repo_name = repo_config.get('name', 'aur-buildbot')
repo_dir = repo_config.get('directory', '/srv/http/aur-buildbot')

packages = config['packages']
architectures = config['architectures']

all_packages = pkg.find_dependencies(packages)

# This is the dictionary that the buildmaster pays attention to. We also use
# a shorter alias to save typing.
c = BuildmasterConfig = {}

####### WORKERS

# The 'workers' list defines the set of recognized workers. Each element is
# a Worker object, specifying a unique worker name and password.  The same
# worker name and password must be configured on the worker.
c['workers'] = [worker.Worker(n, p) for n, p in config['workers'].items()]

# 'protocols' contains information about protocols which master will use for
# communicating with workers. You must define at least 'port' option that workers
# could connect to your master with this protocol.
# 'port' must match the value configured into the workers (with their
# --master option)
c['protocols'] = {'pb': {'port': config.get('port', 7192)}}


####### CHANGESOURCES

# The 'change_source' setting tells the buildmaster how it should find out
# about source code changes.

c['change_source'] = []

# Poll the AUR for changes to each package

try:
    os.mkdir(os.path.join(basedir, 'gitpoller'), mode=0o755)
except FileExistsError:
    pass

for package, info in all_packages.items():
    arch_string = ','.join(info['architectures'])

    c['change_source'].append(changes.GitPoller(pkg.aur_url(package),
        workdir='gitpoller/{}'.format(package), branch='master',
        project=package, category=arch_string, pollinterval=poll_interval,
        pollAtLaunch=True))
    
    # Poll the source repository for VSC packages
    source_number = 0
    if package.endswith('-git'):
        for source in info['sources']:
            if source['vcs'] == 'git' or source['url'].startswith('git://'):
                log.info("Polling git source repository '{url}' for '{pkg}'",
                    url=source['url'], pkg=package)
                c['change_source'].append(changes.GitPoller(source['url'],
                    workdir='gitpoller/{}-{}'.format(package, source_number),
                    project=package, category=arch_string, 
                    pollinterval=poll_interval, pollAtLaunch=True))
                source_number += 1

####### SCHEDULERS

# Configure the Schedulers, which decide how to react to incoming changes.

c['schedulers'] = []


for arch in set(architectures):
    c['schedulers'].append(schedulers.SingleBranchScheduler(
        name=arch,
        change_filter=util.ChangeFilter(category_re='.*{}.*'.format(arch)),
        treeStableTimer=None,
        builderNames=[arch]
    ))

    c['schedulers'].append(schedulers.ForceScheduler(
        name="manual_build_{}".format(arch),
        buttonName="Build package",
        label="Manually build package",
        builderNames=[arch],
        reason=util.FixedParameter(name="reason", default="Manually built package"),
        username=util.FixedParameter(name="username", default=""),

        codebases=[
            util.CodebaseParameter(
                "",
                name="Package",
                branch=util.FixedParameter(name="branch", default="master"),

                # will generate nothing in the form, but revision, repository,
                # and project are needed by buildbot scheduling system so we
                # need to pass a value ("")
                revision=util.FixedParameter(name="revision", default=""),
                # will generate a combo box
                repository=util.FixedParameter(name="repository", default=""),
                project=util.ChoiceStringParameter(
                    name="project",
                    choices=[package for package, package_info in all_packages.items() if arch in package_info['architectures']]
                )
            )
        ]
    ))

####### BUILDERS

# The 'builders' list defines the Builders, which tell Buildbot how to perform a build:
# what steps, and which workers can execute them.  Note that any particular build will
# only take place on one worker.

c['builders'] = []

repo_add_lock = util.MasterLock('repo_add_lock')

class PropertyInitializer(steps.BuildStep):
    def __init__(self, **kwargs):
        super(PropertyInitializer, self).__init__(
            name='Initialize build properties',
            **kwargs
        )

    @defer.inlineCallbacks
    def run(self):
        log = yield self.addLog('output')
    
        # Set dependencies property
        package_info = all_packages[self.getProperty('project')]
        yield log.addStdout('PackageInfo: {}'.format(package_info))
        
        dependencies = set(package_info.get('dependencies', set()))
        yield log.addStdout('Dependencies: {}'.format(dependencies))
        dependencies.update(set(package_info.get('extra_dependencies', set())))
        yield log.addStdout('Dependencies: {}'.format(dependencies))
        dependencies = tuple(dependencies)
        
        yield log.addStdout('Dependencies: {}'.format(dependencies))
        
        self.setProperty('dependencies', dependencies)
        
        return defer.returnValue(util.SUCCESS)

class FindPackageFiles(steps.BuildStep):

    def __init__(self, arch, workdir=None, **kwargs):
        super(FindPackageFiles, self).__init__(
            name='Find built package files',
            workdir=workdir,
            **kwargs
        )
        self.arch = arch

    @defer.inlineCallbacks
    def run(self):
        # make sure the worker knows about glob
        workerver = (self.workerVersion('glob'))
        if not all(workerver):
            raise WorkerTooOldError('need glob')

        cmd = buildbot.process.remotecommand.RemoteCommand('glob', {'path': os.path.join(self.workdir, '*.pkg.tar.xz')})
        yield self.runCommand(cmd)
        
        log = yield self.addLog('output')
        
        if cmd.didFail():
            return defer.returnValue(cmd.results())

        files = cmd.updates["files"][-1]
        if len(files) == 0:
            yield log.addStderr('No package files found')
            return defer.returnValue(util.FAILURE)

        yield log.addStdout('Found package files: {}'.format(files))
        self.build.addStepsAfterCurrentStep([
            UploadRepoAdd(self.arch, files)
        ])

        return defer.returnValue(util.SUCCESS)


class UploadRepoAdd(steps.MultipleFileUpload):
    def __init__(self, arch, package_files):
        super(UploadRepoAdd, self).__init__(
            name='Upload package files',
            workersrcs=package_files, 
            masterdest="{}/{}".format(repo_dir, arch),
            mode=0o644
        )
        self.arch = arch
        self.new_steps = []
    
    def uploadDone(self, result, source, masterdest):
        source = os.path.basename(source)
        # If this is an any package, link to it in all the arch directories
        if self.arch == 'any':
            for real_arch in architectures.keys():
                self.new_steps.append(steps.MasterShellCommand(
                    name='Link \'any\' package to \'{}\' repos'.format(real_arch),
                    command=['ln', '-sf', os.path.join('../any', source), os.path.join(repo_dir, real_arch, source)]
                ))

    def allUploadsDone(self, result, sources, masterdest):
        if self.arch == 'any':
            repo_arches = architectures.keys()
        else:
            repo_arches = [self.arch]
        for repo_arch in repo_arches:
            self.new_steps.append(steps.MasterShellCommand(
                name='Add package to {} repo'.format(repo_arch),
                command=[
                    'repo-add', '-R',
                    os.path.join(repo_dir, repo_arch, '{}.db.tar.gz'.format(repo_name))
                ] + [os.path.join(masterdest, os.path.basename(s)) for s in sources],
                locks=[repo_add_lock.access('exclusive')]
            ))
    
        self.build.addStepsAfterCurrentStep(self.new_steps)

common_steps = [
    PropertyInitializer(),
    steps.Git(
        name='Download package repo',
        repourl=util.Interpolate('https://aur.archlinux.org/%(prop:project)s.git'),
        alwaysUseLatest=True,
        branch='master',
        mode='full',
        method='fresh'
    ),
    steps.ShellCommand(
        name='Build package',
        command=['sudo', 'build-package', util.Property('dependencies', default=tuple())],
        haltOnFailure=True,
        flunkOnFailure=True
    )
]

any_steps = [FindPackageFiles(arch)]
any_factory = util.BuildFactory(common_steps + any_steps)
c['builders'].append(util.BuilderConfig(
    name='any',
    # Get 'any' workers, defaulting to all workers
    workernames=architectures.get('any', config['workers'].keys()),
    factory=any_factory
))

for arch, workers in architectures.items():
    if arch == 'any': continue
    arch_steps = [FindPackageFiles(arch)]
    arch_factory = util.BuildFactory(common_steps + arch_steps)
    c['builders'].append(util.BuilderConfig(
        name=arch,
        workernames=workers,
        factory=arch_factory
    ))


####### BUILDBOT SERVICES

# 'services' is a list of BuildbotService items like reporter targets. The
# status of each build will be pushed to these targets. buildbot/reporters/*.py
# has a variety to choose from, like IRC bots.

c['services'] = []

if 'email' in config:
    email_config = config['email']
    smtp_config = email_config['smtp']
    c['services'].append(reporters.MailNotifier(
        mode=('failing', 'exception', 'warnings'),
        fromaddr=email_config['from'],
        sendToInterestedUsers=False,
        extraRecipients=email_config['to'],
        relayhost=smtp_config['addr'],
        smtpPort=smtp_config.get('port', 587),
        useTls=smtp_config.get('use_tls', True),
        smtpUser=smtp_config['user'],
        smtpPassword=smtp_config['password']
    ))

####### PROJECT IDENTITY

# the 'title' string will appear at the top of this buildbot installation's
# home pages (linked to the 'titleURL').

c['title'] = "AUR Buildbot"
c['titleURL'] = "https://aur.archlinux.org"

# the 'buildbotURL' string should point to the location where the buildbot's
# internal web server is visible. This typically uses the port number set in
# the 'www' entry below, but with an externally-visible host name which the
# buildbot cannot figure out without some help.

c['buildbotURL'] = config['ui']['url']

# minimalistic config to activate new web UI
c['www'] = { 'port': config.get('ui', {}).get('port', 8010), 
             'plugins': dict(waterfall_view={}, console_view={}) }

c['buildbotNetUsageData'] = 'basic'

####### DB URL

c['db'] = {
    # This specifies what database buildbot uses to store its state.  You can leave
    # this at its default for all but the largest installations.
    'db_url' : "sqlite:///state.sqlite",
}
